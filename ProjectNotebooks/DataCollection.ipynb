{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "import requests\n",
    "from pprint import pprint\n",
    "import ftfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ünicode\n"
     ]
    }
   ],
   "source": [
    "#expected ünicode\n",
    "print(ftfy.fix_text('uÌˆnicode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prePage is a soup object \n",
    "def nextPageUrl(prePage):\n",
    "#   resp = requests.get(prePageUrl)\n",
    "#   prePage = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    li = prePage.find(\"li\", {\"class\": \"next sprite\"})\n",
    "    a = li.find('a')\n",
    "    nextPageUrl = a.attrs['href']\n",
    "    #print(nextPageUrl)\n",
    "    return nextPageUrl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newsUrls(pageUrl):\n",
    "    resp = requests.get(pageUrl)\n",
    "    #print(\"request_code:\", resp.status_code)\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    urls = []\n",
    "    for h in soup.find_all(\"div\", {\"class\": \"searchResultsBox\"}):\n",
    "        a = h.find('a')\n",
    "        urls.append(a.attrs['href'])\n",
    "       \n",
    "    return soup, urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "mainUrl = 'https://www.bloomberght.com/tum-ekonomi-haberleri'\n",
    "resp = requests.get(mainUrl)\n",
    "print(resp.status_code)\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/abd-de-issizlik-maasi-basvurulari-beklenenden-yuksek-cikti-2230648',\n",
       " '/kuresel-piyasalar-hisseler-cin-in-misilleme-aciklamasi-ile-dustu-tahviller-yukseldi-2230640',\n",
       " '/spot-piyasada-elektrik-fiyatlari-15082019-2230642',\n",
       " '/sigarada-otv-duzenlemesi-zam-olarak-doner-mi-2230590',\n",
       " '/borsa-gunun-ilk-yarisinda-geriledi-2230637',\n",
       " '/negatif-faizli-tahvil-toplami-16-trilyon-dolarla-rekor-kirdi-2230633',\n",
       " '/cin-abd-10-yeni-tarife-ile-trump-xi-anlasmasini-ihlal-ediyor-2230634',\n",
       " '/ekonomi-basininda-bugun-15-agustos-2019-2230628',\n",
       " '/ingiltere-de-perakende-satislar-yuzde-02-yukseldi-2230629',\n",
       " '/tcmb-repo-ihalesiyle-piyasaya-3-milyar-lira-verdi-2230630']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []\n",
    "for h in soup.find_all(\"div\", {\"class\": \"searchResultsBox\"}):\n",
    "    a = h.find('a')\n",
    "    urls.append(a.attrs['href'])\n",
    "\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.bloomberght.com/abd-de-issizlik-maasi-basvurulari-beklenenden-yuksek-cikti-2230648\n",
      "https://www.bloomberght.com/kuresel-piyasalar-hisseler-cin-in-misilleme-aciklamasi-ile-dustu-tahviller-yukseldi-2230640\n",
      "https://www.bloomberght.com/spot-piyasada-elektrik-fiyatlari-15082019-2230642\n",
      "https://www.bloomberght.com/sigarada-otv-duzenlemesi-zam-olarak-doner-mi-2230590\n",
      "https://www.bloomberght.com/borsa-gunun-ilk-yarisinda-geriledi-2230637\n",
      "https://www.bloomberght.com/negatif-faizli-tahvil-toplami-16-trilyon-dolarla-rekor-kirdi-2230633\n",
      "https://www.bloomberght.com/cin-abd-10-yeni-tarife-ile-trump-xi-anlasmasini-ihlal-ediyor-2230634\n",
      "https://www.bloomberght.com/ekonomi-basininda-bugun-15-agustos-2019-2230628\n",
      "https://www.bloomberght.com/ingiltere-de-perakende-satislar-yuzde-02-yukseldi-2230629\n",
      "https://www.bloomberght.com/tcmb-repo-ihalesiyle-piyasaya-3-milyar-lira-verdi-2230630\n",
      "https://www.bloomberght.com/cavusoglu-guvenli-bolge-abd-nin-oyalama-taktikleri-gecerli-olmayacaktir-2230627\n",
      "https://www.bloomberght.com/norvec-merkez-bankasi-faizi-degistirmedi-2230625\n",
      "https://www.bloomberght.com/merkezi-yonetim-butce-dengesi-99-milyar-tl-fazla-verdi-2230620\n",
      "https://www.bloomberght.com/tcmb-den-repo-ihalesi-2230621\n",
      "https://www.bloomberght.com/konutta-en-ucuz-esenyurt-en-pahali-besiktas-2230622\n",
      "https://www.bloomberght.com/italyan-politik-dramasinda-kritik-hafta-2230609\n",
      "https://www.bloomberght.com/iso-turkiye-ihracat-iklimi-endeksi-temmuz-da-51-3-oldu-2230614\n",
      "https://www.bloomberght.com/unilever-sanayi-ve-ticaret-turk-as-ye-sorusturma-2230613\n",
      "https://www.bloomberght.com/asya-borsalari-gerilerken-hong-kong-pozitif-ayristi-2230580\n",
      "https://www.bloomberght.com/ekonomik-veri-programi-15-agustos-2019-2230612\n",
      "https://www.bloomberght.com/issizlik-orani-mayis-ta-128-oldu-2230600\n",
      "https://www.bloomberght.com/borsa-gune-dususle-basladi-2230608\n",
      "https://www.bloomberght.com/guney-kore-japonya-ya-diyalog-cagrisinda-bulundu-2230601\n",
      "https://www.bloomberght.com/brezilya-10-yildan-sonra-ilk-kez-dolar-satiyor-2230597\n",
      "https://www.bloomberght.com/turkiye-ekonomik-verileri-15-agustos-2019-2230596\n",
      "https://www.bloomberght.com/dolartl-tatil-sonrasi-kayiplarinin-bir-kismini-geri-aldi-2230591\n",
      "https://www.bloomberght.com/deutsche-bank-arjantin-yuzunden-tl-satmayin-2230593\n",
      "https://www.bloomberght.com/serbest-piyasada-doviz-acilis-fiyatlari-15082019-2230592\n",
      "https://www.bloomberght.com/abd-de-tahvil-faizleri-resesyon-alarmi-veriyor-2230587\n",
      "https://www.bloomberght.com/kanada-basbakani-trudeau-etik-kurallari-cignedigini-itiraf-etti-2230588\n"
     ]
    }
   ],
   "source": [
    "pageUrl = mainUrl\n",
    "allNews = []\n",
    "\n",
    "##5 pages scanned\n",
    "for counter in range(3):\n",
    "    prePage, news = newsUrls(pageUrl)\n",
    "    for each in news:\n",
    "        print('https://www.bloomberght.com' + each)\n",
    "    allNews += news\n",
    "    pageUrl = nextPageUrl(prePage)\n",
    "    #for each in news:\n",
    "        #print(each)\n",
    "    #print(\".\", end=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each in allNews:\n",
    "#    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allNews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRawContent(newsUrl):\n",
    "    res = requests.get(\"https://www.bloomberght.com\"+ newsUrl)\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\") \n",
    "\n",
    "    raw_content = soup.findAll(\"p\")\n",
    "    \n",
    "    return raw_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(raw_content):\n",
    "    \n",
    "    document = []\n",
    "    \n",
    "    for par in raw_content:\n",
    "        if par.text != \"\" and not par.find(\"a\") and len(par.text) > 3:\n",
    "            document.append(par.text)\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeText(start,stop):\n",
    "    for url in allNews[start:stop]:\n",
    "        doc = getText(getRawContent(url))\n",
    "        docs.append(doc)\n",
    "        print(\".\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eraseText(untill):\n",
    "    curr_size = len(docs)\n",
    "    if curr_size - untill <= 0:\n",
    "        return\n",
    "    for idx in range(curr_size - untill):\n",
    "        docs.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDuplicateExist(test_list):\n",
    "    \n",
    "    if len(test_list) != len(set(test_list)):\n",
    "        print(\"WARNING!!!! \\n There are duplicates in your list\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"All elements are distinct\")\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def reinterpret_latin1_as_utf8(wrongtext):\n",
    "#    newbytes = wrongtext.encode('latin-1', 'replace')\n",
    "#    return newbytes.decode('utf-8', 'replace')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeToDisk(docs):\n",
    "    f = open(\"TurkishDataSet.txt\", \"a\")\n",
    "    for i in range(len(docs)):\n",
    "        str_doc = ' '.join(docs[i])\n",
    "        str_doc += \"\\n\"\n",
    "        f.write(str_doc)\n",
    "    \n",
    "    f.close() \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in allNews:\n",
    "    rawContent = getRawContent(url)\n",
    "    rawtext = getText(rawContent)\n",
    "    rawtext = ' '.join(rawtext)\n",
    "    text = ftfy.fix_text(rawtext)\n",
    "    docs.append(text)\n",
    "    \n",
    "writeToDisk(docs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60977"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2d array\n",
    "size = 0\n",
    "for i in range(len(docs)):\n",
    "    for j in range (len(docs[i])):\n",
    "        size +=1\n",
    "        \n",
    "size      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ABD'de işsizlik maaşı başvuruları geçen hafta ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Avrupa hisse senetleri, ABD endeks vadeli kont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Enerji Piyasaları İşletme AŞ verilerine göre, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bazı Mallara Uygulanacak Özel Tüketim Vergisi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>İlk yarıda bankacılık endeksi yüzde 4,73, hold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>ABD tahvil piyasalarında çalmaya başlayan rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Çin ABD'nin yüzde 10 yeni tarife ile Trump-Xi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Ekonomi basınında bugün Gazetelerin ekonomi sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>İngiltere'de perakende satışlar  Temmuz'da bek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>İhaleye 4 milyar 500 milyon liralık teklif gel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  docID                                               text\n",
       "0     0  ABD'de işsizlik maaşı başvuruları geçen hafta ...\n",
       "1     1  Avrupa hisse senetleri, ABD endeks vadeli kont...\n",
       "2     2  Enerji Piyasaları İşletme AŞ verilerine göre, ...\n",
       "3     3  Bazı Mallara Uygulanacak Özel Tüketim Vergisi ...\n",
       "4     4  İlk yarıda bankacılık endeksi yüzde 4,73, hold...\n",
       "5     5  ABD tahvil piyasalarında çalmaya başlayan rese...\n",
       "6     6  Çin ABD'nin yüzde 10 yeni tarife ile Trump-Xi ...\n",
       "7     7  Ekonomi basınında bugün Gazetelerin ekonomi sa...\n",
       "8     8  İngiltere'de perakende satışlar  Temmuz'da bek...\n",
       "9     9  İhaleye 4 milyar 500 milyon liralık teklif gel..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"docID\",\"text\"]\n",
    "df = pd.DataFrame(columns = cols)\n",
    "# now fill it up row by row\n",
    "idx = 0\n",
    "for i in range(len(docs)):\n",
    "        df.loc[idx] = [i,docs[i]]\n",
    "\n",
    "        idx+=1\n",
    "df.sort_values([\"docID\"], axis=0, ascending=True, inplace=True) \n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel(join('/Users/cankutcoskun/Desktop/ChatBotProject', 'TurkishDataSet.xlsx'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
